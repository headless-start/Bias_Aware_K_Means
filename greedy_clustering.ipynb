{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "181ee05b-5f76-4975-be2a-c92d21dba918",
      "cell_type": "code",
      "source": "import numpy as np\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\nimport time\n\nREP_FILE = 'representatives.csv'\nASGNMT_FILE = 'assignments.csv'\n\ndef euclidean(a, b):\n    return np.linalg.norm(a - b)\n\ndef worker(chunk, tau):\n    \"\"\"Process a chunk of data to find local representatives.\"\"\"\n    local_representatives = []\n    for x in chunk:\n        assigned = False\n        for r in local_representatives:\n            if euclidean(x, r) < tau:\n                assigned = True\n                break\n        if not assigned:\n            local_representatives.append(x)\n    return local_representatives\n\n\ndef greedy_clustering(file_path, tau, seed, nr_workers):\n    \"\"\"This function applies the greedy clustering algorithm as indicated in the Project instructions.\n\n    Args:\n        file_path (str): file path of the data set\n        tau (int): threshold, if all distances between a data point and the already existing representatives is above the threshold, the data point becomes another representative.\n        seed (int): seed for shuffling\n        nr_workers (int): number of workers/cores used for multiprocessing\n\n    Returns:\n        ratio (float): This is the ratio indicating how much smaller the reduced data set is. E.g. 0.1 means the reduced set has 10% of the capacity of the original data set. It is a value between 0 and 1.\n    \"\"\"\n\n    # Read Data\n    print(\"Read data\")\n    data = np.loadtxt(file_path, delimiter=',')\n    print(f\"Dataset shape: {data.shape}\")\n    rng = np.random.default_rng(seed=seed)\n    rng.shuffle(data)\n    \n    ### TODO: Insert code below\n    chunks = np.array_split(data, nr_workers)\n\n    with Pool(processes=nr_workers) as pool:\n        local_representatives_list = pool.starmap(\n            worker,\n            [(chunk, tau) for chunk in chunks]\n        )\n\n    #Merge local representatives into a global list\n    representatives = []\n    for local_representatives in local_representatives_list:\n        for x in local_representatives:\n            assigned = False\n            for r in representatives:\n                if euclidean(x, r) < tau:\n                    assigned = True\n                    break\n            if not assigned:\n                representatives.append(x)\n\n    #assign each data point to the nearest representative\n    assignments = []\n    for point in data:\n        found = False\n        for idx, rep in enumerate(representatives):\n            if euclidean(point, rep) < tau:\n                assignments.append(idx)\n                found = True\n                break\n        if not found:\n            #assign to nearest representative\n            nearest_rep = np.argmin([euclidean(point, rep) for rep in representatives])\n            assignments.append(nearest_rep)\n\n    ### TODO: Insert code above\n\n    ### Save preprocessed data\n    ### NOTE: the object 'representatives' holds an iterable (list of lists or NumPy ndarray) with the selected representaives in shape (num_representives, 6).\n    ### NOTE: the object 'data_with_labels' holds an iterable (list of lists or NumPy ndarray) with the data points and their assigned cluster (index of representative)\n    ###  in shape (num_data_points, 7) where the last column is the index of the representative from the 'representative' object.\n    data_with_labels = np.hstack(( data, np.array(assignments).reshape((-1,1))))\n    np.savetxt(ASGNMT_FILE, data_with_labels, delimiter=\",\")\n    np.savetxt(REP_FILE, representatives, delimiter=\",\")\n    ratio = len(representatives) / len(data)\n    print(f\"Ratio of representatives: {ratio:.4f}\")  \n    return ratio\n\nif __name__ == \"__main__\":\n    # Define parameters for the clustering and plotting\n    file_path = 'small_dataset.csv'\n    tau_values = [11750, 33.2, 16.351]  #list of threshold values\n    seed = 42\n    nr_workers = 8\n\n    for tau in tau_values:\n        ratio = greedy_clustering(file_path, tau, seed, nr_workers)\n        if ratio is not None:\n            print(f\"For tau={tau}, Ratio of representatives to total data points: {ratio:.4f}\")\n\n    #assert (0.08 < greedy_clustering('dataset.csv', 200, 42, 4) < 0.09) \n    #assert (0.08 < greedy_clustering('small_dataset.csv', 200, 42, 4) < 0.09) \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}